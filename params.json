{"name":"RFUS","tagline":"Rcythr's Fast Userspace Scheduling.","body":"__Version:__ **1.0.2**\r\n\r\n__Release date:__ **2014.03.10**\r\n\r\n__Project state:__ **stable**\r\n\r\n__Author:__ Richard W. Laughlin Jr. (@rcythr)\r\n\r\n***\r\n\r\nThis library allows a user to schedule tasks to be run on a collection of worker threads in a concurrent fashion. First a RFUS implementation must be created and stored in a pointer somewhere. The default is a singleton located in the rfus library.\r\n\t\r\nIn general, Worker-agnostic tasks can be scheduled on \r\n\r\n1. The thread that completes the task. (**Worker Selection**)\r\n\r\n2. The order in which the worker completes his tasks. (**Task Priority**)\r\n\r\nHowever, Tasks which are tied to a particular worker thread can only be scheduled within the worker (**Task Priority**)\r\n\r\n***\t\r\n\r\nCurrently there are four RFUS implementations:\r\n* __ROUND_ROBIN__\r\n\r\n    - Worker selection is ROUND_ROBIN\r\n\r\n    - Tasks are strictly FIFO\r\n\r\n* __ROUND_ROBIN_WITH_PRIORITY__\r\n\r\n    - Worker selection is ROUND_ROBIN\r\n\r\n    - Tasks are reordered to priority\r\n\r\n* __LEAST_BUSY__\r\n\r\n    - Worker selection is onto the least busy worker\r\n\r\n    - Tasks are strictly FIFO\r\n\r\n* __LEAST_BUSY_WITH_PRIORITY__\r\n\r\n    - Worker selection is onto the least busy worker\r\n\r\n    - Tasks are reordered to priority\r\n\r\nEach has benefits and drawbacks which are discussed in the rfus_type.hpp file. The choice of implementation depends largely on the type of tasks you're processing and the rate at which they come in.\r\n\r\n# Usage\r\n\r\nThe code below creates a RFUS and stores it into the global RFUS variable.  The RFUS will schedule worker-agnostic threads in a round robin fashion to the 2 available workers. The workers will grab tasks from the queues 1 at a time.\r\n\r\n        RFUS = createRFUS(ROUND_ROBIN, 2, 1);\r\n\r\nThe code below creates a RFUS and stores it into a custom variable. The RFUS will schedule worker-agnostic threads into the least busy queue at that time for the 5 available workers. The workers will grab tasks from the queues 2 at a time. Additionally the tasks will be ordered in their queues based on their priority (lowest is highest).\r\n\r\n        RFUSInterface* myRFUS = createRFUS(LEAST_BUSY_WITH_PRIORITY, 5, 2);\r\n\r\n## Function Specification\r\nOnce a RFUS has been created it is possible to schedule tasks onto it using the Task helper class. This class has a lot of functions which do similar, but different things. The order in which the arguments are supplied is helpful to understand the semantics.\r\n\r\n+ Functor to Task [Required]\r\n+ Worker ID [Optional]\r\n+ Priority/Deadline [Optional]\r\n\t\r\n## Then Relationships\r\nBelow two tasks are created which will happen, in order, possibly on different threads.\r\n\r\n        RFUS->post(Task(funcA).then(funcB));\r\n\r\n## Also Relationships\r\nBelow two tasks (funcA and funcB) are created which may happen concurrently on two different threads. All following tasks will wait for the also to complete. Afterwards the following task (funcC) will be completed.\r\n\r\n        RFUS->post(Task(funcA).also(funcB).then(funcC));\r\n\r\n## Fork Relationships\r\nBelow two tasks (funcA and funcB) are created which may happen concurrently on two different threads. This is distinct from \"also\" in that it does not block subsequent tasks from executing immediately.\r\n    \r\n        RFUS->post(Task(funcA).fork(funcB).then(funcC));\r\n\r\n## Mixing Then, Also, and Fork Relationships\r\n\"Then\", \"also\", and \"fork\" relationships may be mixed to great effect. A then relationship after an also relationship will cause the then relationship to run only after all of the tasks in the also relationship have completed. \r\n\r\nHowever, fork relationships create independent tasks that will begin when all of the also relationships begin, but will not cause a following then to wait.\r\n\r\nIn the code below funcD will run only after funcA, funcB, and funcC have completed. funcE will begin with funcA, funcB, and funcC, but funcD will not wait for the task to complete.\r\n\r\n        RFUS->post(Task(funcA).also(funcB).also(funcC).fork(funcE).then(funcD));\r\n\r\n## Understanding Priority\r\nIt is also possible (and suggested for priority queues) to supply a priority to each task. RFUS is agnostic to the meaning of the priorities - you can define these however you wish.\r\n\r\nThe code below will use some function currentTime() to get the current time (in ms, ns, s, ...). The first task will be prioritized to the currentTime() the second task will be prioritized to currentTime()+15. The third task will be prioritized to 1500.\r\n\r\nNote: The meaning of the 0 parameter is explained in the next section.\r\n\r\n        RFUS->post(Task([] () {\r\n            printf(\"I HAPPEN FIRST\\n\");\r\n        }, 0, currentTime()).then([] () {\r\n            printf(\"I HAPPEN SECOND\\n\");\r\n        }, 0, 15).thenAbsolute([] () {\r\n            printf(\"I HAPPEN THIRD\\n\");\r\n        }, 0, 1500);\r\n\r\n## Tieing to Workers\r\nFinally it is possible to tie tasks to certain workers. This can be useful to avoid mutexes.\r\n\r\nIn the code below the second task will happen strictly after the first task even though an also relationship is used. This is because the first and second tasks share the same worker. The third task may happen at the same time as either of the two workers. This is because it is tied to a totally different worker than the previous two tasks.\r\n\r\n        RFUS->post(Task([] () {\r\n            printf(\"I HAPPEN FIRST\\n\");\r\n        }, 1).also([] () {\r\n            printf(\"I HAPPEN SECOND\\n\");\r\n        }, 1).also([] () {\r\n            printf(\"I HAPPEN AT THE SAME TIME.\\n\");\r\n        }, 2);\r\n\r\n## Pipelines\r\nPipelines are a helper set of templates that add serious power to the tasking system described above. The pipeline class does nothing that a user could not already do, but simply wraps it in a clean, no-nonsense interface. The following is the typical usage of a pipeline:\r\n\r\n        RFUS->post(Pipeline::start<int>([] () {\r\n            return 42;\r\n        }).then([] (int value) {\r\n            printf(\"%d\\n\", value);\r\n        }).close());\r\n\r\nIn the above code the first task is scheduled and returns a value of 42. This value is stored on the heap and then passed into the second task. The second task does not return a value and thus can be closed. The close() function returns a task_t* similar to the Task helper class. In fact, the Pipeline template uses the Task class internally.\r\n\r\nPipelines support the same **action**, **[worker]**, **[deadline]** function arguments as the Task class. \r\n\r\nIdeally pipelines will always end with a function that returns void. However, in many cases this is not possible, so instead of adding a dummy function at the end of the pipeline, resources can be saved by using endWith instead of then. For example:\r\n\r\n        RFUS->post(Pipeline::start<int>([] () {\r\n            return 42;\r\n        }).closeWith<bool>([] (int value) {\r\n            printf(\"%d\\n\", value);\r\n            return true;\r\n        }));\r\n\r\nNo resources will be allocated for the bool returned from the final function. This value will simply be discarded after it is returned. closeWith returns a task_t* the same as close() does for tasks returning void.\r\n\r\nPipelines can be tricky because there are three types of pipelines:\r\n* Normal Pipeline (Takes a parameter)\r\n* Void Pipeline (Does not take a parameter)\r\n* Forked Pipeline (Takes Parameter, Parameter is shared)\r\n\r\nWhen you are working with pipelines you do not need to specify which type of pipeline to create - this is done automatically. You simply need to be aware what operations are available to you based on the current pipeline.\r\n\r\nThe Pipeline::start() function handles the first  transition from a void pipeline to a normal pipeline for you automatically. Thus pipelines always start in the normal state. The following table shows the effects of various member functions on the state of the pipeline:\r\n\r\n### Normal Pipeline\r\n+ then w/ return val      -> Normal Pipeline\r\n+ then w/o return val     -> Void Pipeline\r\n+ split w/ return val     -> Forked Pipeline\r\n+ split w/o return val    -> Forked Pipeline\r\n\r\n### Void Pipeline\r\n*** then w/ return val      -> Normal Pipeline\r\n*** then w/o return val     -> Void Pipeline\r\n*** also w/ return val      -> Normal Pipeline\r\n*** also w/o retrun val     -> Void Pipeline\r\n*** fork w/ return val      -> Void Pipeline\r\n*** fork w/o return val     -> Void Pipeline\r\n    \r\n### Forked Pipeline\r\n*** also w/ return val      -> Forked Pipeline\r\n*** also w/o return val     -> Forked Pipeline\r\n*** join w/ return val      -> Normal Pipeline\r\n*** join w/o return val     -> Void Pipeline\r\n*** fork w/ return val      -> Forked Pipeline\r\n*** fork w/o return val     -> Forked Pipeline\r\n\r\nVoid pipelines and Forked pipelines support the fork operation. This operation simply spins off another task that takes the result of the previous operation (if any). No tasks will wait for this task to complete. It is completely indepedent.\r\n\r\nNormal and Void pipelines support the then operation. The then operation will complete the given task after the last task(s) have completed (exclusing forks). If you only use the then operation you will never find yourself in the Forked Pipeline.\r\n\r\nIf you use the split function in the Normal Pipeline you will find yourself in the Forked Pipeline. The return value before the split will be passed into all subsequent calls up to and including the join call that leaves the Forked Pipeline. Thus the split is equivalent to a then that can share the return value from before it with subsequent calls. All return values in the Forked Pipeline are ignored except for the final \"join\" call that leaves the Forked Pipeline. The example below illustrates the sematics of the Forked Pipeline.\r\n\r\n        RFUS->post(Pipeline::start<int>([] () {\r\n            return 42;\r\n        }).split<int>([] (int val) { // In: 42, Out: 45.\r\n            return val+3;\r\n        }).also<void>([] (int val) { // In 42\r\n            printf(\"%d\\n\", val);\r\n        }).also<int>([] (int val) {  // In 42, Out 45 (discarded)\r\n            return val+3;\r\n        }).join<int>([] (int val) {  // In 42, Out 46\r\n            printf(\"%d\\n\", val);\r\n            return val+4;\r\n        }).then([] (int val) {      // In 46\r\n            printf(\"%d\\n\", val);\r\n        }).close()); \r\n\r\nThe above \"split\", \"also\", \"also\" (w/ return), and \"join\" calls all happen concurrently. If the pipeline were a Task class the split would be a then and the rest would be \"also\" calls. \r\n\r\nOther than taking care to use split and join correctly the usage of the pipeline system should be fairly straightforward.\r\n\r\n# Dependencies:\r\n\r\n* C++11 Standard Compliant Compiler (Clang 3.1, GCC 4.8, Etc). Older versions than the above *may* work depending on compliance.\r\n\r\n# Installation Instructions\r\n\r\nOn linux or mingw simply type \"make\". The static library will be in the /lib directory and all the necessary includes will be in /include.\r\n\r\nOn other systems simply use your compiler to build the .cc files into a static library. From there use the **rfus.h**, **rfus_type.h**, **task.h**, **join_semaphore.h**, and **pipeline.h** files as includes.\r\n\r\n# Documentation\r\n\r\nDocumentation may be found in the associated .hpp files and in code.\r\n\r\n# Changelog\r\n\r\n    1.0.1 - Pipeline implementation.\r\n    1.0.0 - Basic implementation is complete with continuations and joins.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}