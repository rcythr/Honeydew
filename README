Rcythr's Fast Userspace Scheduling
-------------------------------------------------------------------------------
Version 1.0.0
Release date: 2014.03.10
-------------------------------------------------------------------------------
Project state:
	stable
-------------------------------------------------------------------------------
Credits
	Richard W. Laughlin Jr.
------------------------------------------------------------------------------
Project description

This library allows a user to schedule tasks to be run on a collection 
of worker threads in a concurrent fashion. First a RFUS implementation 
must be created and stored in a pointer somewhere. The default is a 
singleton located in the rfus library.
	
Worker-agnostic tasks can be scheduled on 
	1. The worker that completes the task (Worker Selection)
	2. The order in which the worker completes the task (Priority)
	
Tasks which are tied to a particular worker thread can only be 
scheduled within the worker (priority)
	
Currently there are 4 RFUS implementations:
	* ROUND_ROBIN 
		Worker selection is ROUND_ROBIN
		Tasks are strictly FIFO
	* ROUND_ROBIN_WITH_PRIORITY 
		Worker selection is ROUND_ROBIN
		Tasks are reordered to priority
	* LEAST_BUSY 
		Worker selection is onto the least busy worker
		Tasks are strictly FIFO
	* LEAST_BUSY_WITH_PRIORITY 
		Worker selection is onto the least busy worker
		Tasks are reordered to priority

Each has benefits and drawbacks which are discussed in the rfus_type.hpp
file. The choice of implementation depends largely on the type 
of tasks you're processing and the rate at which they come in.

------------------------------------------------------------------------------
Usage

== Creation ==

The code below creates a RFUS and stores it into the global RFUS 
variable.  The RFUS will schedule worker-agnostic threads in a 
round robin fashion to the 2 available workers. The workers will
grab tasks from the queues 1 at a time.

	RFUS = createRFUS(ROUND_ROBIN, 2, 1);

The code below creates a RFUS and stores it into a custom variable.  
The RFUS will schedule worker-agnostic threads into the least busy 
queue at that time for the 5 available workers. The workers will grab 
tasks from the queues 2 at a time. Additionally the tasks will be 
ordered in their queues based on their priority (lowest is highest).

	RFUSInterface* myRFUS = createRFUS(LEAST_BUSY_WITH_PRIORITY, 5, 2);

== Function Specification ==
Once a RFUS has been created it is possible to schedule tasks onto it 
using the Task helper class. This class has a lot of functions which do 
similar, but different things. The order in which the arguments are 
supplied is helpful to understand the semantics.

	[Optional] Worker ID
	[Required] Functor to Task
	[Optional] Priority/Deadline
	
== Then Relationships ==
Below two tasks are created which will happen, in order, possibly on different 
threads.

	RFUS->post(Task(funcA).then(funcB));

== Also Relationships ==
Below two tasks (funcA and funcB) are created which may happen concurrently on 
two different threads. All following tasks will wait for the also to complete. 
Afterwards the following task (funcC) will be completed.

	RFUS->post(Task(funcA).also(funcB).then(funcC));

== Fork Relationships ==
Below two tasks (funcA and funcB) are created which may happen concurrently on 
two different threads. This is distinct from "also" in that it does not block 
subsequent tasks from executing immediately.
    
    RFUS->post(Task(funcA).fork(funcB).then(funcC));

== Mixing Then, Also, and Fork Relationships ==
"Then", "also", and "fork" relationships may be mixed to great effect. A then 
relationship after an also relationship will cause the then relationship to 
run only after all of the tasks in the also relationship have completed. 

However, fork relationships create independent tasks that will begin when all
of the also relationships begin, but will not cause a following then to wait.

In the code below funcD will run only after funcA, funcB, and funcC have 
completed. funcE will begin with funcA, funcB, and funcC, but funcD will not
wait for the task to complete.

	RFUS->post(Task(funcA).also(funcB).also(funcC).fork(funcE).then(funcD));

== Understanding Priority ==
It is also possible (and suggested for priority queues) to supply a priority 
to each task. RFUS is agnostic to the meaning of the priorities - you can 
define these however you wish.

The code below will use some function currentTime() to get the current time 
(in ms, ns, s, ...). The first task will be prioritized to the currentTime() 
the second task will be prioritized to currentTime()+15. The third task will 
be prioritized to 1500.

Note: The meaning of the 0 parameter is explained in the next section.

	RFUS->post(Task([] () {
		printf("I HAPPEN FIRST\n");
	}, 0, currentTime()).then([] () {
		printf("I HAPPEN SECOND\n");
	}, 0, 15).thenAbsolute([] () {
		printf("I HAPPEN THIRD\n");
	}, 0, 1500);

== Tieing to Workers ==
Finally it is possible to tie tasks to certain workers. This can be useful to 
avoid mutexes.

In the code below the second task will happen strictly after the first task 
even though an also relationship is used. This is because the first and second 
tasks share the same worker. The third task may happen at the same time as 
either of the two workers. This is because it is tied to a totally different 
worker than the previous two tasks.

	RFUS->post(Task([] () {
		printf("I HAPPEN FIRST\n");
	}, 1).also([] () {
		printf("I HAPPEN SECOND\n");
	}, 1).also([] () {
		printf("I HAPPEN AT THE SAME TIME.\n");
	}, 2);

== Pipelines ==
Pipelines are a helper set of templates that add serious power to the tasking
system described above. The pipeline class does nothing that a user could not
already do, but simply wraps it in a clean, no-nonsense interface.

The following is the typical usage of a pipeline:

    RFUS->post(Pipeline::start<int>([] () {
        return 42;
    }).then([] (int value) {
        printf("%d\n", value);
    }).close());

In the above code the first task is scheduled and returns a value of 42. This
value is stored on the heap and then passed into the second task. The second
task does not return a value and thus can be closed. The close() function
returns a task_t* similar to the Task helper class. In fact, the Pipeline
template uses the Task class internally.

Pipelines support the same [worker], action, [deadline] function arguments as the
Task class. 

Ideally pipelines will always end with a function that returns void. However,
in many cases this is not possible, so instead of adding a dummy function at the
end of the pipeline, resources can be saved by using endWith instead of then.
For example:

    RFUS->post(Pipeline::start<int>([] () {
        return 42;
    }).closeWith<bool>([] (int value) {
        printf("%d\n", value);
        return true;
    }));

No resources will be allocated for the bool returned from the final function.
This value will simply be discarded after it is returned. closeWith returns a
task_t* the same as close() does for tasks returning void.

Pipelines can be tricky because there are three types of pipelines:
    * Normal Pipeline (Takes a parameter)
    * Void Pipeline (Does not take a parameter)
    * Forked Pipeline (Takes Parameter, Parameter is shared)

When you are working with pipelines you do not need to specify which type of
pipeline to create - this is done automatically. You simply need to be aware
what operations are available to you based on the current pipeline.

The Pipeline::start() function handles the first  transition from a void pipeline 
to a normal pipeline for you automatically. Thus pipelines always start in the
normal state. The following table shows the effects of various member functions
on the state of the pipeline:

Normal Pipeline
    then w/ return val      -> Normal Pipeline
    then w/o return val     -> Void Pipeline
    split w/ return val     -> Forked Pipeline
    split w/o return val    -> Forked Pipeline

Void Pipeline
    then w/ return val      -> Normal Pipeline
    then w/o return val     -> Void Pipeline
    also w/ return val      -> Normal Pipeline
    also w/o retrun val     -> Void Pipeline
    fork w/ return val      -> Void Pipeline
    fork w/o return val     -> Void Pipeline
    
Forked Pipeline
    also w/ return val      -> Forked Pipeline
    also w/o return val     -> Forked Pipeline
    join w/ return val      -> Normal Pipeline
    join w/o return val     -> Void Pipeline
    fork w/ return val      -> Forked Pipeline
    fork w/o return val     -> Forked Pipeline

Void pipelines and Forked pipelines support the fork operation. This operation simply 
spins off another task that takes the result of the previous operation (if any). 
No tasks will wait for this task to complete. It is completely indepedent.

Normal and Void pipelines support the then operation. The then operation will complete
the given task after the last task(s) have completed (exclusing forks). If you
only use the then operation you will never find yourself in the Forked Pipeline.

If you use the split function in the Normal Pipeline you will find yourself in the
Forked Pipeline. The return value before the split will be passed into all subsequent 
calls up to and including the join call that leaves the Forked Pipeline. Thus the split
is equivalent to a then that can share the return value from before it with subsequent
calls. All return values in the Forked Pipeline are ignored except for the final "join" 
call that leaves the Forked Pipeline. The example below illustrates the sematics of 
the Forked Pipeline.

    RFUS->post(Pipeline::start<int>([] () {
        return 42;
    }).split<int>([] (int val) { // In: 42, Out: 45.
        return val+3;
    }).also<void>([] (int val) { // In 42
        printf("%d\n", val);
    }).also<int>([] (int val) {  // In 42, Out 45 (discarded)
        return val+3;
    }).join<int>([] (int val) {  // In 42, Out 46
        printf("%d\n", val);
        return val+4;
    }).then([] (int val) {      // In 46
        printf("%d\n", val);
    }).close()); 

The above "split", "also", "also" (w/ return), and "join" calls all happen concurrently.
If the pipeline were a Task class the split would be a then and the rest would be "also" calls. 

Other than taking care to use split and join correctly the usage of the pipeline system should
be fairly straightforward.

-------------------------------------------------------------------------------
Dependencies:

* C++11 Standard Compliant Compiler (Clang 3.1, GCC 4.8, Etc)
	Older versions than the above *may* work depending on compliance.

-------------------------------------------------------------------------------
Installation Instructions

On linux or mingw simply type "make". The static library will be in the /lib 
directory and all the necessary includes will be in /include.

On other systems simply use your compiler to build the .cc files into a static
library. From there use the rfus.h, rfus_type.h, and task.h files as includes.

-------------------------------------------------------------------------------
Documentation
	Documentation may be found in the associated .hpp files and in code.

-------------------------------------------------------------------------------
Changelog

	1.0.0 - Basic implementation is complete with continuations and joins.
